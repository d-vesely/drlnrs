{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dvesely\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dvesely\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import src.constants as constants\n",
    "from src.common_utils import read_pickled_data\n",
    "from src.data.preprocessing_news_utils import read_data_news, preprocess_data_news, concat_data_news\n",
    "from src.data.preprocessing_behaviors_utils import read_data_behaviors, preprocess_data_behaviors, get_time_data, concat_data_behaviors\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Behaviors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensions and Columns\n",
    "\n",
    "We examine the behavior data dimensions and columns of each split. For a detailed explanation of how these splits were constructed, refer to the accompanying work. All splits have the same set of columns, but the test set does not include labels in the `impression` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (2232748, 5) -- data columns: ['id', 'user_id', 'time', 'history', 'impression']\n",
      "dev data shape: (376471, 5) -- data columns: ['id', 'user_id', 'time', 'history', 'impression']\n",
      "test data shape: (2370727, 5) -- data columns: ['id', 'user_id', 'time', 'history', 'impression']\n"
     ]
    }
   ],
   "source": [
    "splits = [\"train\", \"dev\", \"test\"]\n",
    "# Iterate over all splits, read data, print dimensions and columns\n",
    "for i, path in enumerate([constants.TRAIN_PATH, constants.DEV_PATH, constants.TEST_PATH]):\n",
    "    data_behaviors = read_data_behaviors(path)\n",
    "    print(f\"{splits[i]} data shape: {data_behaviors.shape} -- data columns: {data_behaviors.columns.to_list()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two cells show samples from the labeled data and unlabeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>time</th>\n",
       "      <th>history</th>\n",
       "      <th>impression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>U134050</td>\n",
       "      <td>11/15/2019 8:55:22 AM</td>\n",
       "      <td>N12246 N128820 N119226 N4065 N67770 N33446 N10...</td>\n",
       "      <td>N91737-0 N30206-0 N54368-0 N117802-0 N18190-0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>U254959</td>\n",
       "      <td>11/15/2019 11:42:35 AM</td>\n",
       "      <td>N34011 N9375 N67397 N7936 N118985 N109453 N103...</td>\n",
       "      <td>N119999-0 N24958-0 N104054-0 N33901-0 N9250-0 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  user_id                    time  \\\n",
       "0   1  U134050   11/15/2019 8:55:22 AM   \n",
       "1   2  U254959  11/15/2019 11:42:35 AM   \n",
       "\n",
       "                                             history  \\\n",
       "0  N12246 N128820 N119226 N4065 N67770 N33446 N10...   \n",
       "1  N34011 N9375 N67397 N7936 N118985 N109453 N103...   \n",
       "\n",
       "                                          impression  \n",
       "0  N91737-0 N30206-0 N54368-0 N117802-0 N18190-0 ...  \n",
       "1  N119999-0 N24958-0 N104054-0 N33901-0 N9250-0 ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_behaviors_labeled = read_data_behaviors(constants.DEV_PATH)\n",
    "data_behaviors_labeled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>time</th>\n",
       "      <th>history</th>\n",
       "      <th>impression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>U64099</td>\n",
       "      <td>11/19/2019 11:37:45 AM</td>\n",
       "      <td>N121133 N104200 N43255 N55860 N128965 N38014 N...</td>\n",
       "      <td>N101071 N15647 N83400 N124838 N57092 N64623 N6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>U231077</td>\n",
       "      <td>11/19/2019 5:28:08 AM</td>\n",
       "      <td>N45124 N84730 N45128 N104312 N70022 N99111 N26...</td>\n",
       "      <td>N14657 N51253 N49521 N126571 N74286 N101071 N1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  user_id                    time  \\\n",
       "0   1   U64099  11/19/2019 11:37:45 AM   \n",
       "1   2  U231077   11/19/2019 5:28:08 AM   \n",
       "\n",
       "                                             history  \\\n",
       "0  N121133 N104200 N43255 N55860 N128965 N38014 N...   \n",
       "1  N45124 N84730 N45128 N104312 N70022 N99111 N26...   \n",
       "\n",
       "                                          impression  \n",
       "0  N101071 N15647 N83400 N124838 N57092 N64623 N6...  \n",
       "1  N14657 N51253 N49521 N126571 N74286 N101071 N1...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_behaviors_unlabeled = read_data_behaviors(constants.TEST_PATH)\n",
    "data_behaviors_unlabeled.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenations\n",
    "\n",
    "We create concatenated sets of the data for further use. Namely:\n",
    "- A full training set (`trainfull`), containing training and dev data. The data is pickled to `CONCAT_TRAINFULL_PATH`.\n",
    "- A full dataset (`all`), containing all splits. The data is pickled to `CONCAT_ALL_PATH`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenated full training data shape: (2609219, 5)\n",
      "concatenated full data shape: (4979946, 5)\n"
     ]
    }
   ],
   "source": [
    "# Read all splits\n",
    "data_behaviors_train = read_data_behaviors(constants.TRAIN_PATH)\n",
    "data_behaviors_dev = read_data_behaviors(constants.DEV_PATH)\n",
    "data_behaviors_test = read_data_behaviors(constants.TEST_PATH)\n",
    "\n",
    "# Create trainfull data\n",
    "data_behaviors_trainfull_list = [\n",
    "    data_behaviors_train,\n",
    "    data_behaviors_dev\n",
    "]\n",
    "data_behaviors_trainfull = concat_data_behaviors(\n",
    "    data_behaviors_trainfull_list,\n",
    "    save_dir=constants.CONCAT_TRAINFULL_PATH\n",
    ")\n",
    "print(f\"concatenated full training data shape: {data_behaviors_trainfull.shape}\")\n",
    "\n",
    "# Create all data\n",
    "data_behaviors_list = [\n",
    "    data_behaviors_trainfull,\n",
    "    data_behaviors_test\n",
    "]\n",
    "data_behaviors = concat_data_behaviors(\n",
    "    data_behaviors_list,\n",
    "    save_dir=constants.CONCAT_ALL_PATH\n",
    ")\n",
    "print(f\"concatenated full data shape: {data_behaviors.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "The main preprocessing routine is started in the cells below. The first cell runs the preprocessing on the training data (`train`, `dev`, `trainfull`), the second cell on the `test` data. All preprocessed data is pickled into the same directory as the original data, in a subdirectory `./preprocessed`. Exploratory data has a `exp_` prefix in the filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== PREPROCESSING TRAIN DATA ====\n",
      "[INFO] preprocessed data will be saved in ../dataset_MIND\\MINDlarge_train\\preprocessed\n",
      "[INFO] converting timestamp data\n",
      "[INFO] splitting reading history\n",
      "[INFO] separating impression column\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2232748/2232748 [00:28<00:00, 78707.25it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] sorting data\n",
      "[INFO] processing user histories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2232748/2232748 [00:13<00:00, 167985.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving preprocessed data\n",
      "[INFO] obtaining exploration data\n",
      "[INFO] saving exploratory data\n",
      "[INFO] collecting set of relevant news IDs\n",
      "[INFO] saving relevant news data\n",
      "==== PREPROCESSING DEV DATA ====\n",
      "[INFO] preprocessed data will be saved in ../dataset_MIND\\MINDlarge_dev\\preprocessed\n",
      "[INFO] converting timestamp data\n",
      "[INFO] splitting reading history\n",
      "[INFO] separating impression column\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 376471/376471 [00:05<00:00, 63264.53it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] sorting data\n",
      "[INFO] processing user histories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 376471/376471 [00:01<00:00, 371042.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving preprocessed data\n",
      "[INFO] obtaining exploration data\n",
      "[INFO] saving exploratory data\n",
      "[INFO] collecting set of relevant news IDs\n",
      "[INFO] saving relevant news data\n",
      "==== PREPROCESSING TRAINFULL DATA ====\n",
      "[INFO] preprocessed data will be saved in ../dataset_MIND\\MINDlarge_trainfull\\preprocessed\n",
      "[INFO] converting timestamp data\n",
      "[INFO] splitting reading history\n",
      "[INFO] separating impression column\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2609219/2609219 [00:35<00:00, 73828.11it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] sorting data\n",
      "[INFO] processing user histories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2609219/2609219 [00:13<00:00, 194239.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving preprocessed data\n",
      "[INFO] obtaining exploration data\n",
      "[INFO] saving exploratory data\n",
      "[INFO] collecting set of relevant news IDs\n",
      "[INFO] saving relevant news data\n"
     ]
    }
   ],
   "source": [
    "training_data_paths = [constants.TRAIN_PATH, constants.DEV_PATH, constants.CONCAT_TRAINFULL_PATH]\n",
    "split_names = [\"TRAIN DATA\", \"DEV DATA\", \"TRAINFULL DATA\"]\n",
    "for i, path in enumerate(training_data_paths):\n",
    "    print(f\"==== PREPROCESSING {split_names[i]} ====\")\n",
    "    # Concatenated data is pickled\n",
    "    if i == 2:\n",
    "        data_behaviors = read_pickled_data([path, \"behaviors_concat.pkl\"])\n",
    "    else:\n",
    "        data_behaviors = read_data_behaviors(path)\n",
    "    \n",
    "    pp_data_behaviors = preprocess_data_behaviors(\n",
    "        data_behaviors,\n",
    "        save_dir=path,\n",
    "        test_data=False,\n",
    "        exploration=True,\n",
    "        get_relevant_news=True,\n",
    "        save_user_histories=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== PREPROCESSING TRAIN DATA ====\n",
      "[INFO] preprocessed data will be saved in ../../dataset_MIND\\MINDlarge_train\\preprocessed\n",
      "[INFO] converting timestamp data\n",
      "[INFO] splitting reading history\n",
      "[INFO] separating impression column\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2232748/2232748 [00:29<00:00, 75534.66it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] sorting data\n",
      "[INFO] processing user histories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2232748/2232748 [00:18<00:00, 122059.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving preprocessed data\n",
      "==== PREPROCESSING DEV DATA ====\n",
      "[INFO] preprocessed data will be saved in ../../dataset_MIND\\MINDlarge_dev\\preprocessed\n",
      "[INFO] converting timestamp data\n",
      "[INFO] splitting reading history\n",
      "[INFO] separating impression column\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 376471/376471 [00:02<00:00, 151578.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] sorting data\n",
      "[INFO] processing user histories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 376471/376471 [00:01<00:00, 320118.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving preprocessed data\n",
      "==== PREPROCESSING TRAINFULL DATA ====\n",
      "[INFO] preprocessed data will be saved in ../../dataset_MIND\\MINDlarge_trainfull\\preprocessed\n",
      "[INFO] converting timestamp data\n",
      "[INFO] splitting reading history\n",
      "[INFO] separating impression column\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2609219/2609219 [00:34<00:00, 75997.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] sorting data\n",
      "[INFO] processing user histories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2609219/2609219 [00:24<00:00, 107369.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving preprocessed data\n"
     ]
    }
   ],
   "source": [
    "training_data_paths = [constants.TRAIN_PATH, constants.DEV_PATH, constants.CONCAT_TRAINFULL_PATH]\n",
    "split_names = [\"TRAIN DATA\", \"DEV DATA\", \"TRAINFULL DATA\"]\n",
    "for i, path in enumerate(training_data_paths):\n",
    "    print(f\"==== PREPROCESSING {split_names[i]} ====\")\n",
    "    # Concatenated data is pickled\n",
    "    if i == 2:\n",
    "        data_behaviors = read_pickled_data([path, \"behaviors_concat.pkl\"])\n",
    "    else:\n",
    "        data_behaviors = read_data_behaviors(path)\n",
    "    \n",
    "    pp_data_behaviors = preprocess_data_behaviors(\n",
    "        data_behaviors,\n",
    "        save_dir=path,\n",
    "        save_name_suffix=\"_ignore_history\",\n",
    "        test_data=False,\n",
    "        exploration=False,\n",
    "        get_relevant_news=False,\n",
    "        save_user_histories=False,\n",
    "        build_ignore_history=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== PREPROCESSING TEST DATA ====\n",
      "[INFO] preprocessed data will be saved in ../dataset_MIND\\MINDlarge_test\\preprocessed\n",
      "[INFO] converting timestamp data\n",
      "[INFO] splitting reading history\n",
      "[INFO] splitting impression column\n",
      "[INFO] saving preprocessed data\n",
      "[INFO] collecting set of relevant news IDs\n",
      "[INFO] saving relevant news data\n"
     ]
    }
   ],
   "source": [
    "data_behaviors = read_data_behaviors(constants.TEST_PATH)\n",
    "\n",
    "print(f\"==== PREPROCESSING TEST DATA ====\")\n",
    "pp_data_behaviors_test = preprocess_data_behaviors(\n",
    "    data_behaviors,\n",
    "    save_dir=constants.TEST_PATH,\n",
    "    test_data=True,\n",
    "    exploration=False,\n",
    "    get_relevant_news=True,\n",
    "    save_user_histories=False\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessed Data NaN Check\n",
    "\n",
    "Simple sanity check to confirm that the data contains no `NaN` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id              0\n",
      "user_id         0\n",
      "history         0\n",
      "timestamp       0\n",
      "clicked_news    0\n",
      "ignored_news    0\n",
      "shown_news      0\n",
      "dtype: int64\n",
      "id              0\n",
      "user_id         0\n",
      "history         0\n",
      "timestamp       0\n",
      "clicked_news    0\n",
      "ignored_news    0\n",
      "shown_news      0\n",
      "dtype: int64\n",
      "id            0\n",
      "user_id       0\n",
      "history       0\n",
      "timestamp     0\n",
      "shown_news    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "splits = [\"train\", \"dev\", \"test\"]\n",
    "for i, path in enumerate([constants.TRAIN_PATH, constants.DEV_PATH, constants.TEST_PATH]):\n",
    "    data_behaviors = read_pickled_data([path, \"preprocessed\", \"behaviors.pkl\"])\n",
    "    print(data_behaviors.isna().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenated Preprocessed Data\n",
    "\n",
    "The following cell concatenates the preprocessed data over all splits. This will be needed for obtaining survival data for each news during the news preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenated full data shape: (4979946, 2)\n"
     ]
    }
   ],
   "source": [
    "# Create preprocessed folder\n",
    "save_dir = os.path.join(constants.CONCAT_ALL_PATH, \"preprocessed\")\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Load all splits and only keep shown_news and timestamp columns\n",
    "# Only the two columns are needed for obtaining survival data\n",
    "# The concatenated data is otherwise unused\n",
    "data_behaviors_train = read_pickled_data([constants.TRAIN_PATH, \"preprocessed\", \"behaviors.pkl\"])[[\"shown_news\", \"timestamp\"]]\n",
    "data_behaviors_dev = read_pickled_data([constants.DEV_PATH, \"preprocessed\", \"behaviors.pkl\"])[[\"shown_news\", \"timestamp\"]]\n",
    "data_behaviors_test = read_pickled_data([constants.TEST_PATH, \"preprocessed\", \"behaviors.pkl\"])[[\"shown_news\", \"timestamp\"]]\n",
    "data_behaviors_list = [\n",
    "    data_behaviors_train,\n",
    "    data_behaviors_dev,\n",
    "    data_behaviors_test\n",
    "]\n",
    "\n",
    "# Concatenate all splits\n",
    "data_behaviors = concat_data_behaviors(data_behaviors_list, save_dir=save_dir)\n",
    "print(f\"concatenated full data shape: {data_behaviors.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Heads\n",
    "\n",
    "The following cells show examples of the preprocessed data. For labeled data, the `dev` split is shown, because it is small and thus loads quickly."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of the minimal preprocessed behaviors data (without additional columns with exploratory data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>history</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>clicked_news</th>\n",
       "      <th>ignored_news</th>\n",
       "      <th>shown_news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>2783</td>\n",
       "      <td>U1</td>\n",
       "      <td>[N14639, N27258, N63237, N112729, N42180, N109...</td>\n",
       "      <td>2019-11-15 08:13:43</td>\n",
       "      <td>[N69938]</td>\n",
       "      <td>[N19162, N83491, N121138, N94999, N44453, N807...</td>\n",
       "      <td>[N19162, N83491, N121138, N94999, N44453, N807...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46868</th>\n",
       "      <td>46869</td>\n",
       "      <td>U1</td>\n",
       "      <td>[N14639, N27258, N63237, N112729, N42180, N109...</td>\n",
       "      <td>2019-11-15 10:36:07</td>\n",
       "      <td>[N104644]</td>\n",
       "      <td>[N121138, N7728, N56565, N69938, N4331, N20802...</td>\n",
       "      <td>[N121138, N104644, N7728, N56565, N69938, N433...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id user_id                                            history  \\\n",
       "2782    2783      U1  [N14639, N27258, N63237, N112729, N42180, N109...   \n",
       "46868  46869      U1  [N14639, N27258, N63237, N112729, N42180, N109...   \n",
       "\n",
       "                timestamp clicked_news  \\\n",
       "2782  2019-11-15 08:13:43     [N69938]   \n",
       "46868 2019-11-15 10:36:07    [N104644]   \n",
       "\n",
       "                                            ignored_news  \\\n",
       "2782   [N19162, N83491, N121138, N94999, N44453, N807...   \n",
       "46868  [N121138, N7728, N56565, N69938, N4331, N20802...   \n",
       "\n",
       "                                              shown_news  \n",
       "2782   [N19162, N83491, N121138, N94999, N44453, N807...  \n",
       "46868  [N121138, N104644, N7728, N56565, N69938, N433...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_behaviors_labeled = read_pickled_data([constants.DEV_PATH, \"preprocessed\", \"behaviors.pkl\"])\n",
    "data_behaviors_labeled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>history</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>clicked_news</th>\n",
       "      <th>ignored_news</th>\n",
       "      <th>shown_news</th>\n",
       "      <th>ignore_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>2783</td>\n",
       "      <td>U1</td>\n",
       "      <td>[N14639, N27258, N63237, N112729, N42180, N109...</td>\n",
       "      <td>2019-11-15 08:13:43</td>\n",
       "      <td>[N69938]</td>\n",
       "      <td>[N19162, N83491, N121138, N94999, N44453, N807...</td>\n",
       "      <td>[N19162, N83491, N121138, N94999, N44453, N807...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46868</th>\n",
       "      <td>46869</td>\n",
       "      <td>U1</td>\n",
       "      <td>[N14639, N27258, N63237, N112729, N42180, N109...</td>\n",
       "      <td>2019-11-15 10:36:07</td>\n",
       "      <td>[N104644]</td>\n",
       "      <td>[N121138, N7728, N56565, N69938, N4331, N20802...</td>\n",
       "      <td>[N121138, N104644, N7728, N56565, N69938, N433...</td>\n",
       "      <td>[N19162, N83491, N121138, N94999, N44453, N807...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id user_id                                            history  \\\n",
       "2782    2783      U1  [N14639, N27258, N63237, N112729, N42180, N109...   \n",
       "46868  46869      U1  [N14639, N27258, N63237, N112729, N42180, N109...   \n",
       "\n",
       "                timestamp clicked_news  \\\n",
       "2782  2019-11-15 08:13:43     [N69938]   \n",
       "46868 2019-11-15 10:36:07    [N104644]   \n",
       "\n",
       "                                            ignored_news  \\\n",
       "2782   [N19162, N83491, N121138, N94999, N44453, N807...   \n",
       "46868  [N121138, N7728, N56565, N69938, N4331, N20802...   \n",
       "\n",
       "                                              shown_news  \\\n",
       "2782   [N19162, N83491, N121138, N94999, N44453, N807...   \n",
       "46868  [N121138, N104644, N7728, N56565, N69938, N433...   \n",
       "\n",
       "                                          ignore_history  \n",
       "2782                                                  []  \n",
       "46868  [N19162, N83491, N121138, N94999, N44453, N807...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_behaviors_labeled = read_pickled_data([constants.DEV_PATH, \"preprocessed\", \"behaviors_ignore_history.pkl\"])\n",
    "data_behaviors_labeled.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessed `test` split of the behaviors data has no `clicked_news` and `ignored_news` columns (the labels are not available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>history</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>shown_news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>U64099</td>\n",
       "      <td>[N121133, N104200, N43255, N55860, N128965, N3...</td>\n",
       "      <td>2019-11-19 11:37:45</td>\n",
       "      <td>[N101071, N15647, N83400, N124838, N57092, N64...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>U231077</td>\n",
       "      <td>[N45124, N84730, N45128, N104312, N70022, N991...</td>\n",
       "      <td>2019-11-19 05:28:08</td>\n",
       "      <td>[N14657, N51253, N49521, N126571, N74286, N101...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  user_id                                            history  \\\n",
       "0   1   U64099  [N121133, N104200, N43255, N55860, N128965, N3...   \n",
       "1   2  U231077  [N45124, N84730, N45128, N104312, N70022, N991...   \n",
       "\n",
       "            timestamp                                         shown_news  \n",
       "0 2019-11-19 11:37:45  [N101071, N15647, N83400, N124838, N57092, N64...  \n",
       "1 2019-11-19 05:28:08  [N14657, N51253, N49521, N126571, N74286, N101...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_behaviors_test = read_pickled_data([constants.TEST_PATH, \"preprocessed\", \"behaviors.pkl\"])\n",
    "data_behaviors_test.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of the preprocessed labeled data with additional exploratory columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>history</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>clicked_news</th>\n",
       "      <th>ignored_news</th>\n",
       "      <th>shown_news</th>\n",
       "      <th>clicked_news_length</th>\n",
       "      <th>ignored_news_length</th>\n",
       "      <th>shown_news_length</th>\n",
       "      <th>clicked_news_percent</th>\n",
       "      <th>ignored_news_percent</th>\n",
       "      <th>ts_date</th>\n",
       "      <th>ts_time</th>\n",
       "      <th>ts_hour</th>\n",
       "      <th>time_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>2783</td>\n",
       "      <td>U1</td>\n",
       "      <td>[N14639, N27258, N63237, N112729, N42180, N109...</td>\n",
       "      <td>2019-11-15 08:13:43</td>\n",
       "      <td>[N69938]</td>\n",
       "      <td>[N19162, N83491, N121138, N94999, N44453, N807...</td>\n",
       "      <td>[N19162, N83491, N121138, N94999, N44453, N807...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>93.750000</td>\n",
       "      <td>2019-11-15</td>\n",
       "      <td>08:13:43</td>\n",
       "      <td>8</td>\n",
       "      <td>morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46868</th>\n",
       "      <td>46869</td>\n",
       "      <td>U1</td>\n",
       "      <td>[N14639, N27258, N63237, N112729, N42180, N109...</td>\n",
       "      <td>2019-11-15 10:36:07</td>\n",
       "      <td>[N104644]</td>\n",
       "      <td>[N121138, N7728, N56565, N69938, N4331, N20802...</td>\n",
       "      <td>[N121138, N104644, N7728, N56565, N69938, N433...</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>5.882353</td>\n",
       "      <td>94.117647</td>\n",
       "      <td>2019-11-15</td>\n",
       "      <td>10:36:07</td>\n",
       "      <td>10</td>\n",
       "      <td>morning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id user_id                                            history  \\\n",
       "2782    2783      U1  [N14639, N27258, N63237, N112729, N42180, N109...   \n",
       "46868  46869      U1  [N14639, N27258, N63237, N112729, N42180, N109...   \n",
       "\n",
       "                timestamp clicked_news  \\\n",
       "2782  2019-11-15 08:13:43     [N69938]   \n",
       "46868 2019-11-15 10:36:07    [N104644]   \n",
       "\n",
       "                                            ignored_news  \\\n",
       "2782   [N19162, N83491, N121138, N94999, N44453, N807...   \n",
       "46868  [N121138, N7728, N56565, N69938, N4331, N20802...   \n",
       "\n",
       "                                              shown_news  clicked_news_length  \\\n",
       "2782   [N19162, N83491, N121138, N94999, N44453, N807...                    1   \n",
       "46868  [N121138, N104644, N7728, N56565, N69938, N433...                    1   \n",
       "\n",
       "       ignored_news_length  shown_news_length  clicked_news_percent  \\\n",
       "2782                    15                 16              6.250000   \n",
       "46868                   16                 17              5.882353   \n",
       "\n",
       "       ignored_news_percent     ts_date   ts_time  ts_hour time_category  \n",
       "2782              93.750000  2019-11-15  08:13:43        8       morning  \n",
       "46868             94.117647  2019-11-15  10:36:07       10       morning  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_behaviors_exp = read_pickled_data([constants.DEV_PATH, \"preprocessed\", \"exp_behaviors.pkl\"])\n",
    "data_behaviors_exp.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data containing numeric value stats for certain exploratory columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clicked_news_length</th>\n",
       "      <th>ignored_news_length</th>\n",
       "      <th>shown_news_length</th>\n",
       "      <th>clicked_news_percent</th>\n",
       "      <th>ignored_news_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>376471.000000</td>\n",
       "      <td>376471.000000</td>\n",
       "      <td>376471.00000</td>\n",
       "      <td>376471.000000</td>\n",
       "      <td>376471.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.526930</td>\n",
       "      <td>35.887789</td>\n",
       "      <td>37.41472</td>\n",
       "      <td>10.014902</td>\n",
       "      <td>89.985098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.169522</td>\n",
       "      <td>39.174353</td>\n",
       "      <td>39.62298</td>\n",
       "      <td>11.596071</td>\n",
       "      <td>11.596071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.334448</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>2.941176</td>\n",
       "      <td>87.804878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>5.882353</td>\n",
       "      <td>94.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>51.00000</td>\n",
       "      <td>12.195122</td>\n",
       "      <td>97.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>119.00000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>98.837209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>185.00000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>99.270073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>298.000000</td>\n",
       "      <td>299.00000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>99.665552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       clicked_news_length  ignored_news_length  shown_news_length  \\\n",
       "count        376471.000000        376471.000000       376471.00000   \n",
       "mean              1.526930            35.887789           37.41472   \n",
       "std               1.169522            39.174353           39.62298   \n",
       "min               1.000000             1.000000            2.00000   \n",
       "25%               1.000000             9.000000           10.00000   \n",
       "50%               1.000000            21.000000           23.00000   \n",
       "75%               2.000000            49.000000           51.00000   \n",
       "95%               4.000000           117.000000          119.00000   \n",
       "99%               6.000000           182.000000          185.00000   \n",
       "max              39.000000           298.000000          299.00000   \n",
       "\n",
       "       clicked_news_percent  ignored_news_percent  \n",
       "count         376471.000000         376471.000000  \n",
       "mean              10.014902             89.985098  \n",
       "std               11.596071             11.596071  \n",
       "min                0.334448             20.000000  \n",
       "25%                2.941176             87.804878  \n",
       "50%                5.882353             94.117647  \n",
       "75%               12.195122             97.058824  \n",
       "95%               50.000000             98.837209  \n",
       "99%               50.000000             99.270073  \n",
       "max               80.000000             99.665552  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_stats = read_pickled_data([constants.DEV_PATH, \"preprocessed\", \"exp_stats.pkl\"])\n",
    "data_stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data containing initial user histories. The non-exploratory version of this dataframe just omits the `history_length` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>history</th>\n",
       "      <th>history_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U0</td>\n",
       "      <td>[N39011, N112324, N78884, N111503, N63941, N68...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U1</td>\n",
       "      <td>[N14639, N27258, N63237, N112729, N42180, N109...</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U10</td>\n",
       "      <td>[N85722, N111503, N104737]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U100</td>\n",
       "      <td>[N99587, N61339, N129790, N12721, N100405, N10...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U1000</td>\n",
       "      <td>[N33446, N20131, N65823, N65823, N111503, N399...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id                                            history  history_length\n",
       "0      U0  [N39011, N112324, N78884, N111503, N63941, N68...               8\n",
       "1      U1  [N14639, N27258, N63237, N112729, N42180, N109...              72\n",
       "2     U10                         [N85722, N111503, N104737]               3\n",
       "3    U100  [N99587, N61339, N129790, N12721, N100405, N10...              43\n",
       "4   U1000  [N33446, N20131, N65823, N65823, N111503, N399...               9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_users_exp = read_pickled_data([constants.CONCAT_TRAINFULL_PATH, \"preprocessed\", \"exp_users.pkl\"])\n",
    "data_users_exp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    750434.000000\n",
       "mean         18.313292\n",
       "std          23.889606\n",
       "min           0.000000\n",
       "25%           5.000000\n",
       "50%          10.000000\n",
       "75%          22.000000\n",
       "90%          42.000000\n",
       "99%         117.000000\n",
       "max         801.000000\n",
       "Name: history_length, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_users_exp[\"history_length\"].describe(percentiles=[0.25, 0.5, 0.75, 0.9, 0.99])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevant News\n",
    "\n",
    "The relevant news data contains for each news ID that occurs in the corresponding behaviors data, two boolean values. `shown` is `True`, if the news occurred in an impression. `history` is `True` if the news ID occured in one of the initial user histories. Both can be `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train relevant news data shape: (101527, 3)\n",
      "dev relevant news data shape: (72023, 3)\n",
      "trainfull relevant news data shape: (104151, 3)\n",
      "test relevant news data shape: (120961, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_id</th>\n",
       "      <th>shown</th>\n",
       "      <th>history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N129135</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N108581</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N90655</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N114087</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N111452</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   news_id  shown  history\n",
       "0  N129135  False     True\n",
       "1  N108581   True     True\n",
       "2   N90655  False     True\n",
       "3  N114087  False     True\n",
       "4  N111452  False     True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = [\"train\", \"dev\", \"trainfull\", \"test\"]\n",
    "for i, path in enumerate([constants.TRAIN_PATH, constants.DEV_PATH, constants.CONCAT_TRAINFULL_PATH, constants.TEST_PATH]):\n",
    "    relevant_news = read_pickled_data([path, \"preprocessed\", \"relevant_news.pkl\"])\n",
    "    print(f\"{splits[i]} relevant news data shape: {relevant_news.shape}\")\n",
    "\n",
    "relevant_news.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell displays the number of unique news IDs in each split and over the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 101527 relevant news in the train set\n",
      "There are 72023 relevant news in the dev set\n",
      "There are 104151 relevant news in the trainfull set\n",
      "There are 120961 relevant news in the test set\n",
      "There are 130379 relevant news in the union of all sets\n"
     ]
    }
   ],
   "source": [
    "splits = [\"train\", \"dev\", \"trainfull\", \"test\"]\n",
    "rel_news_sets = []\n",
    "rel_news_data_list = []\n",
    "\n",
    "# Get set of relevant news IDs for each split\n",
    "for i, path in enumerate([constants.TRAIN_PATH, constants.DEV_PATH, constants.CONCAT_TRAINFULL_PATH, constants.TEST_PATH]):\n",
    "    relevant_news = read_pickled_data([path, \"preprocessed\", \"relevant_news.pkl\"])\n",
    "    rel_news_data_list.append(relevant_news)\n",
    "\n",
    "    rel_news_set = set(relevant_news[\"news_id\"])\n",
    "    print(f\"There are {len(rel_news_set)} relevant news in the {splits[i]} set\")\n",
    "    rel_news_sets.append(rel_news_set)\n",
    "\n",
    "# Get union of all unique news IDs\n",
    "union_rel_news = set.union(*rel_news_sets)\n",
    "print(f\"There are {len(union_rel_news)} relevant news in the union of all sets\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell calculates the percentage of news IDs that occurred in the dataset only in an impression, only in an initial user history, or both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25% (32871) of the relevant news were just shown.\n",
      "58% (75798) of the relevant news were just in a user history.\n",
      "17% (21710) of the relevant news were both shown and in a user history.\n"
     ]
    }
   ],
   "source": [
    "# Concat all relevant news dataframes\n",
    "data_relevant_news = pd.concat(rel_news_data_list)\n",
    "data_relevant_news = data_relevant_news.groupby(by=\"news_id\").any().reset_index()\n",
    "\n",
    "# Count news that occurred only in an impression, only in a history or both\n",
    "shown_rel_news = (data_relevant_news[\"shown\"] & ~data_relevant_news[\"history\"]).sum()\n",
    "history_rel_news = (~data_relevant_news[\"shown\"] & data_relevant_news[\"history\"]).sum()\n",
    "both_rel_news = (data_relevant_news[\"shown\"] & data_relevant_news[\"history\"]).sum()\n",
    "\n",
    "# Print information\n",
    "print(f\"{shown_rel_news / len(union_rel_news) * 100:.0f}% ({shown_rel_news}) of the relevant news were just shown.\")\n",
    "print(f\"{history_rel_news / len(union_rel_news) * 100:.0f}% ({history_rel_news}) of the relevant news were just in a user history.\")\n",
    "print(f\"{both_rel_news / len(union_rel_news) * 100:.0f}% ({both_rel_news}) of the relevant news were both shown and in a user history.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timestamp Information\n",
    "\n",
    "The following cell shows the time spans of the individual splits. For a detailed explanation of how these splits were constructed, refer to the accompanying work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time data:\n",
      "{'min': Timestamp('2019-11-09 00:00:00'), 'max': Timestamp('2019-11-14 23:59:59'), 'span': Timedelta('5 days 23:59:59')}\n",
      "dev time data:\n",
      "{'min': Timestamp('2019-11-15 00:00:00'), 'max': Timestamp('2019-11-15 23:59:43'), 'span': Timedelta('0 days 23:59:43')}\n",
      "trainfull time data:\n",
      "{'min': Timestamp('2019-11-09 00:00:00'), 'max': Timestamp('2019-11-15 23:59:43'), 'span': Timedelta('6 days 23:59:43')}\n",
      "test time data:\n",
      "{'min': Timestamp('2019-11-16 00:00:05'), 'max': Timestamp('2019-11-22 23:59:58'), 'span': Timedelta('6 days 23:59:53')}\n"
     ]
    }
   ],
   "source": [
    "splits = [\"train\", \"dev\", \"trainfull\", \"test\"]\n",
    "for i, path in enumerate([constants.TRAIN_PATH, constants.DEV_PATH, constants.CONCAT_TRAINFULL_PATH, constants.TEST_PATH]):\n",
    "    data_behaviors = read_pickled_data([path, \"preprocessed\", \"behaviors.pkl\"])\n",
    "    time_data = get_time_data(data_behaviors)\n",
    "    print(f\"{splits[i]} time data:\\n{time_data}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users\n",
    "\n",
    "We can count the number of unique users in each split using the users data, containing the initial histories for each unique user in the split. For the test data, we have to use the behaviors data and count the number of unique user IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 711222 users in the train set\n",
      "There are 255990 users in the dev set\n",
      "There are 702005 users in the test set\n",
      "There are 876956 users in the union of all sets\n",
      "There are 188592 users in the intersection of all sets\n"
     ]
    }
   ],
   "source": [
    "train_users = set(read_pickled_data([constants.TRAIN_PATH, \"preprocessed\", \"users.pkl\"])[\"user_id\"])\n",
    "dev_users = set(read_pickled_data([constants.DEV_PATH, \"preprocessed\", \"users.pkl\"])[\"user_id\"])\n",
    "test_users = set(read_pickled_data([constants.TEST_PATH, \"preprocessed\", \"behaviors.pkl\"])[\"user_id\"].unique())\n",
    "\n",
    "print(f\"There are {len(train_users)} users in the train set\")\n",
    "print(f\"There are {len(dev_users)} users in the dev set\")\n",
    "print(f\"There are {len(test_users)} users in the test set\")\n",
    "\n",
    "union = set.union(*[train_users, dev_users, test_users])\n",
    "intersection = set.intersection(*[train_users, dev_users, test_users])\n",
    "print(f\"There are {len(union)} users in the union of all sets\")\n",
    "print(f\"There are {len(intersection)} users in the intersection of all sets\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data News\n",
    "\n",
    "### Dimensions and Columns\n",
    "\n",
    "We examine the news dataset split dimensions and columns. Each split contains data for the news that occur in the corresponding behaviors data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (101527, 8) -- data columns: ['news_id', 'category', 'sub_category', 'title', 'abstract', 'url', 'title_entities', 'abstract_entities']\n",
      "dev data shape: (72023, 8) -- data columns: ['news_id', 'category', 'sub_category', 'title', 'abstract', 'url', 'title_entities', 'abstract_entities']\n",
      "test data shape: (120959, 8) -- data columns: ['news_id', 'category', 'sub_category', 'title', 'abstract', 'url', 'title_entities', 'abstract_entities']\n"
     ]
    }
   ],
   "source": [
    "splits = [\"train\", \"dev\", \"test\"]\n",
    "# Iterate over all splits, read data, print dimensions and columns\n",
    "for i, path in enumerate([constants.TRAIN_PATH, constants.DEV_PATH, constants.TEST_PATH]):\n",
    "    data_news = read_data_news(path)\n",
    "    print(f\"{splits[i]} data shape: {data_news.shape} -- data columns: {data_news.columns.to_list()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenations\n",
    "\n",
    "We create a concatenated set of the data for further use. The concatenated set will contain no duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenated data shape: (130379, 8)\n"
     ]
    }
   ],
   "source": [
    "data_news_train = read_data_news(constants.TRAIN_PATH)\n",
    "data_news_dev = read_data_news(constants.DEV_PATH)\n",
    "data_news_test = read_data_news(constants.TEST_PATH)\n",
    "data_news_list = [\n",
    "    data_news_train,\n",
    "    data_news_dev,\n",
    "    data_news_test\n",
    "]\n",
    "data_news = concat_data_news(data_news_list, save_dir=constants.CONCAT_ALL_PATH)\n",
    "print(f\"concatenated data shape: {data_news.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "The main preprocessing routine is started in the cells below. Only the concatenated news data is preprocessed. The preprocessed data is pickled into the same directory as the original data, in a subdirectory `./preprocessed`. Exploratory data has a `exp_` prefix in the filename. Data prepared for embedding has a `emb_` prefix in the filename. It requires the preprocessed `trainfull` behaviors data and the concatenated, preprocessed behaviors data over all splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] preprocessed data will be saved in ../../dataset_MIND\\MINDlarge_all\\preprocessed\n",
      "[INFO] replacing NA abstracts with empty string\n",
      "[INFO] remapping categories\n",
      "[INFO] saving\n",
      "[INFO] dropping columns irrelevant for embedding\n",
      "[INFO] concatenating title and abstract\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597c4da7e2a9430099d94206388525cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] concatenating all\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f30786fd654d97befdb95e01b1f661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving data for embedding\n"
     ]
    }
   ],
   "source": [
    "data_news = read_pickled_data([constants.CONCAT_ALL_PATH, \"news_concat.pkl\"])\n",
    "behaviors_paths = {\n",
    "    \"survival\": os.path.join(constants.CONCAT_ALL_PATH, \"preprocessed\"),\n",
    "    \"engagement\": os.path.join(constants.CONCAT_TRAINFULL_PATH, \"preprocessed\")\n",
    "}\n",
    "data_news = preprocess_data_news(\n",
    "    data_news,\n",
    "    save_dir=constants.CONCAT_ALL_PATH,\n",
    "    exploration=False,\n",
    "    behaviors_paths=behaviors_paths,\n",
    "    embedding=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] preprocessed data will be saved in c:\\workbench\\developer\\drlnrs\\dataset_MIND\\MINDlarge_all\\preprocessed\n",
      "[INFO] replacing NA abstracts with empty string\n",
      "[INFO] remapping categories\n",
      "[INFO] saving\n",
      "[INFO] dropping columns irrelevant for embedding\n",
      "[INFO] concatenating title and abstract\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae505b32e6a4d2eb99691c9323a25bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] concatenating all\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4552fa0b0a3d4257b83ccd66854bf191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving data for embedding\n",
      "[INFO] preprocessing title and abstract\n",
      "\t[INFO] lowercasing title\n",
      "\t[INFO] tokenizing title\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "189b87365cb54faea3a9a6c81a3fb657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[INFO] removing punctuation in title\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95cae55dca804487ba301c2816ad31c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[INFO] cleaning contractions in title\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b99d7fcd614c4f65b1617c5461bbd846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[INFO] removing stopwords in title\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2487dc9ee7ad4b9fba63ff1c69d377f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[INFO] lowercasing abstract\n",
      "\t[INFO] tokenizing abstract\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af78230148c4409a363eb505ea95fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[INFO] removing punctuation in abstract\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c263583561144a8d9212d06167165a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[INFO] cleaning contractions in abstract\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc2a539c185f41d78e12732cdfded26a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[INFO] removing stopwords in abstract\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd0e87b9dc541ef81f2ae4f3668cce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] obtaining length stats for title and abstract\n",
      "[INFO] loading behaviors data\n",
      "[INFO] obtaining survival data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b9bdaa5edd459a92909355677124c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4979946 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processing survival data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e47452c17e9e4266a696fd33787c2fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading behaviors data\n",
      "[INFO] obtaining engagement data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae56aecd97bd49229ed76d6f4be7075b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2232748 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processing engagement data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c031d4bf2fb2470a933237ee410de66d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving exploratory data\n"
     ]
    }
   ],
   "source": [
    "data_news = read_pickled_data([constants.CONCAT_ALL_PATH, \"news_concat.pkl\"])\n",
    "behaviors_paths = {\n",
    "    \"survival\": os.path.join(constants.CONCAT_ALL_PATH, \"preprocessed\"),\n",
    "    # Depending on whether this is for statistics, or training, choose path\n",
    "    # \"engagement\": os.path.join(constants.CONCAT_TRAINFULL_PATH, \"preprocessed\")\n",
    "    \"engagement\": os.path.join(constants.TRAIN_PATH, \"preprocessed\")\n",
    "}\n",
    "data_news = preprocess_data_news(\n",
    "    data_news,\n",
    "    save_dir=constants.CONCAT_ALL_PATH,\n",
    "    exploration=True,\n",
    "    behaviors_paths=behaviors_paths,\n",
    "    embedding=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessed Data NaN Check\n",
    "\n",
    "Simple sanity check to confirm that the data contains no `NaN` values. Note that there are 75798 `NaT` values in the `first_read_timestamp` column, which corresponds to the number of news that are just in a user history, and not in an impression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news_id                                       0\n",
      "category                                      0\n",
      "sub_category                                  0\n",
      "title                                         0\n",
      "abstract                                      0\n",
      "url                                           1\n",
      "title_entities                                6\n",
      "abstract_entities                             9\n",
      "title_tokens                                  0\n",
      "title_tokens_no_stopwords                     0\n",
      "abstract_tokens                               0\n",
      "abstract_tokens_no_stopwords                  0\n",
      "title_length                                  0\n",
      "title_no_stopwords_length                     0\n",
      "abstract_length                               0\n",
      "abstract_no_stopwords_length                  0\n",
      "title_and_abstract_length                     0\n",
      "title_and_abstract_no_stopwords_length        0\n",
      "survival_time_hrs                             0\n",
      "first_read_timestamp                      75798\n",
      "clicked                                       0\n",
      "ignored                                       0\n",
      "shown                                         0\n",
      "engagement_percentage                         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_news = read_pickled_data([constants.CONCAT_ALL_PATH, \"preprocessed\", \"exp_news.pkl\"])\n",
    "print(data_news.isna().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Heads\n",
    "\n",
    "The following cells show examples of the preprocessed data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of the minimal preprocessed news data (without additional columns with exploratory data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_id</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "      <th>title_entities</th>\n",
       "      <th>abstract_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N88753</td>\n",
       "      <td>lifestyle</td>\n",
       "      <td>lifestyleroyals</td>\n",
       "      <td>The Brands Queen Elizabeth, Prince Charles, an...</td>\n",
       "      <td>Shop the notebooks, jackets, and more that the...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAGH0ET.html</td>\n",
       "      <td>[{\"Label\": \"Prince Philip, Duke of Edinburgh\",...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N45436</td>\n",
       "      <td>news</td>\n",
       "      <td>newsscienceandtechnology</td>\n",
       "      <td>Walmart Slashes Prices on Last-Generation iPads</td>\n",
       "      <td>Apple's new iPad releases bring big deals on l...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AABmf2I.html</td>\n",
       "      <td>[{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...</td>\n",
       "      <td>[{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  news_id   category              sub_category  \\\n",
       "0  N88753  lifestyle           lifestyleroyals   \n",
       "1  N45436       news  newsscienceandtechnology   \n",
       "\n",
       "                                               title  \\\n",
       "0  The Brands Queen Elizabeth, Prince Charles, an...   \n",
       "1    Walmart Slashes Prices on Last-Generation iPads   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Shop the notebooks, jackets, and more that the...   \n",
       "1  Apple's new iPad releases bring big deals on l...   \n",
       "\n",
       "                                             url  \\\n",
       "0  https://assets.msn.com/labs/mind/AAGH0ET.html   \n",
       "1  https://assets.msn.com/labs/mind/AABmf2I.html   \n",
       "\n",
       "                                      title_entities  \\\n",
       "0  [{\"Label\": \"Prince Philip, Duke of Edinburgh\",...   \n",
       "1  [{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...   \n",
       "\n",
       "                                   abstract_entities  \n",
       "0                                                 []  \n",
       "1  [{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_news = read_pickled_data([constants.CONCAT_ALL_PATH, \"preprocessed\", \"news.pkl\"])\n",
    "data_news.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of the preprocessed data with additional exploratory columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_id</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "      <th>title_entities</th>\n",
       "      <th>abstract_entities</th>\n",
       "      <th>title_tokens</th>\n",
       "      <th>title_tokens_no_stopwords</th>\n",
       "      <th>...</th>\n",
       "      <th>abstract_length</th>\n",
       "      <th>abstract_no_stopwords_length</th>\n",
       "      <th>title_and_abstract_length</th>\n",
       "      <th>title_and_abstract_no_stopwords_length</th>\n",
       "      <th>survival_time_hrs</th>\n",
       "      <th>first_read_timestamp</th>\n",
       "      <th>clicked</th>\n",
       "      <th>ignored</th>\n",
       "      <th>shown</th>\n",
       "      <th>engagement_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N88753</td>\n",
       "      <td>lifestyle</td>\n",
       "      <td>lifestyleroyals</td>\n",
       "      <td>the brands queen elizabeth, prince charles, an...</td>\n",
       "      <td>shop the notebooks, jackets, and more that the...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAGH0ET.html</td>\n",
       "      <td>[{\"Label\": \"Prince Philip, Duke of Edinburgh\",...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[the, brands, queen, elizabeth, prince, charle...</td>\n",
       "      <td>[brands, queen, elizabeth, prince, charles, pr...</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>161.186389</td>\n",
       "      <td>2019-11-11 07:55:42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N45436</td>\n",
       "      <td>news</td>\n",
       "      <td>newsscienceandtechnology</td>\n",
       "      <td>walmart slashes prices on last-generation ipads</td>\n",
       "      <td>apple's new ipad releases bring big deals on l...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AABmf2I.html</td>\n",
       "      <td>[{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...</td>\n",
       "      <td>[{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...</td>\n",
       "      <td>[walmart, slashes, prices, on, last-generation...</td>\n",
       "      <td>[walmart, slashes, prices, last-generation, ip...</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  news_id   category              sub_category  \\\n",
       "0  N88753  lifestyle           lifestyleroyals   \n",
       "1  N45436       news  newsscienceandtechnology   \n",
       "\n",
       "                                               title  \\\n",
       "0  the brands queen elizabeth, prince charles, an...   \n",
       "1    walmart slashes prices on last-generation ipads   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  shop the notebooks, jackets, and more that the...   \n",
       "1  apple's new ipad releases bring big deals on l...   \n",
       "\n",
       "                                             url  \\\n",
       "0  https://assets.msn.com/labs/mind/AAGH0ET.html   \n",
       "1  https://assets.msn.com/labs/mind/AABmf2I.html   \n",
       "\n",
       "                                      title_entities  \\\n",
       "0  [{\"Label\": \"Prince Philip, Duke of Edinburgh\",...   \n",
       "1  [{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...   \n",
       "\n",
       "                                   abstract_entities  \\\n",
       "0                                                 []   \n",
       "1  [{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...   \n",
       "\n",
       "                                        title_tokens  \\\n",
       "0  [the, brands, queen, elizabeth, prince, charle...   \n",
       "1  [walmart, slashes, prices, on, last-generation...   \n",
       "\n",
       "                           title_tokens_no_stopwords  ... abstract_length  \\\n",
       "0  [brands, queen, elizabeth, prince, charles, pr...  ...              12   \n",
       "1  [walmart, slashes, prices, last-generation, ip...  ...              11   \n",
       "\n",
       "  abstract_no_stopwords_length  title_and_abstract_length  \\\n",
       "0                            7                         23   \n",
       "1                           10                         17   \n",
       "\n",
       "   title_and_abstract_no_stopwords_length  survival_time_hrs  \\\n",
       "0                                      15         161.186389   \n",
       "1                                      15           0.000000   \n",
       "\n",
       "   first_read_timestamp  clicked  ignored  shown engagement_percentage  \n",
       "0   2019-11-11 07:55:42        0        1      1                   0.0  \n",
       "1                   NaT        0        0      0                   0.0  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_news = read_pickled_data([constants.CONCAT_ALL_PATH, \"preprocessed\", \"exp_news.pkl\"])\n",
    "data_news.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of the preprocessed data prepared for embedding tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>title_and_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N88753</td>\n",
       "      <td>The Brands Queen Elizabeth, Prince Charles, an...</td>\n",
       "      <td>Shop the notebooks, jackets, and more that the...</td>\n",
       "      <td>The Brands Queen Elizabeth, Prince Charles, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N45436</td>\n",
       "      <td>Walmart Slashes Prices on Last-Generation iPads</td>\n",
       "      <td>Apple's new iPad releases bring big deals on l...</td>\n",
       "      <td>Walmart Slashes Prices on Last-Generation iPad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  news_id                                              title  \\\n",
       "0  N88753  The Brands Queen Elizabeth, Prince Charles, an...   \n",
       "1  N45436    Walmart Slashes Prices on Last-Generation iPads   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Shop the notebooks, jackets, and more that the...   \n",
       "1  Apple's new iPad releases bring big deals on l...   \n",
       "\n",
       "                                  title_and_abstract  \n",
       "0  The Brands Queen Elizabeth, Prince Charles, an...  \n",
       "1  Walmart Slashes Prices on Last-Generation iPad...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_news = read_pickled_data([constants.CONCAT_ALL_PATH, \"preprocessed\", \"emb_news.pkl\"])\n",
    "data_news.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All/Relevant News\n",
    "\n",
    "We construct a set of unique news IDs (the IDs in the news data should already be unique). We can then check whether all news we have data for occur in the behaviors data and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 130379 news in the concatenated dataset (train+dev+test)\n",
      "There are 0 irrelevant news in the data\n",
      "The sets of all news and all relevant news are equal: True\n"
     ]
    }
   ],
   "source": [
    "all_news = set(data_news[\"news_id\"].unique())\n",
    "print(f\"There are {len(all_news)} news in the concatenated dataset (train+dev+test)\")\n",
    "\n",
    "irrelevant_news = all_news.difference(union_rel_news)\n",
    "print(f\"There are {len(irrelevant_news)} irrelevant news in the data\")\n",
    "print(f\"The sets of all news and all relevant news are equal: {all_news == union_rel_news}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnrs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "c3a871892b3c67473474f80d2a65da800da93289bc0b004e1295ce64be9e1442"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
